if [@type] in ["syslog", "relp"] {
    # syslog/relp
  
  grok {
      match => { "@message" => "(?:%{INT:syslog6587_msglen} )?<%{POSINT:syslog_pri}>(?:%{NONNEGINT:syslog5424_ver} )?(?:%{SYSLOGTIMESTAMP:syslog_timestamp}|%{TIMESTAMP_ISO8601:syslog_timestamp}) %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?(:)? %{GREEDYDATA:syslog_message}" }
      match => { "@message" => "<%{POSINT:syslog_pri}>%{SYSLOGTIMESTAMP:syslog_timestamp} %{DATA:syslog_program}\[%{POSINT:syslog_pid}\]: %{GREEDYDATA:syslog_message}" }
      add_tag => [ "syslog_standard" ]
      add_field => { "@raw" => "%{@message}"}
      tag_on_failure => ["fail/syslog_standard/_grokparsefailure"]
  }
  
  if !("fail/syslog_standard/_grokparsefailure" in [tags]) {
      syslog_pri { }
  
      date {
          match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
          timezone => "UTC"
          remove_field => "syslog_timestamp"
      }
  
      # Populate @source.host
      mutate {
          add_field => [ "[@source][host]", "%{syslog_hostname}" ]
      }
  
      mutate {
          convert => [ "syslog5424_ver", "integer" ]
          convert => [ "syslog6587_msglen", "integer" ]
      }
  
      if [syslog5424_ver] == 1 {
          grok {
              # I don't think this is rfc5424-legal because it says SD *must* exist and message *may* exist.
              # However, this makes parsing compatible with common syslog implementations.
              match => [ "syslog_message", "(?:%{DATA:syslog_procid}|\-) (?:%{DATA:syslog_msgid}|\-)(?: %{SYSLOG5424SD:syslog_sd}| \-)? %{GREEDYDATA:syslog_message}" ]
              overwrite => [
                  "syslog_message"
              ]
              tag_on_failure => [ "fail/syslog_standard/_grokparsefailure-syslog_standard-5424" ]
          }
  
          # structured-data
          if [syslog_sd] {
              grok {
                  match => [ "syslog_sd", "\[%{DATA:syslog_sd_id} (?<syslog_sd_params_raw]>[^\]]+)\]" ]
                  remove_field => [
                      "syslog_sd"
                  ]
                  tag_on_failure => [ "fail/syslog_standard/_grokparsefailure-syslog_standard-5424/sds" ]
              }
  
              if !("fail/syslog_standard/_grokparsefailure-syslog_standard-5424/sd" in [tags]) {
                  # convert the the key-value pairs
                  kv {
                      source => "syslog_sd_params_raw"
                      target => "syslog_sd_params"
                      remove_field => [
                          "syslog_sd_params_raw"
                      ]
                  }
                  # When an additional host is specified in the sd_params, promote syslog_hostname to @shipper.host
                  # and replace @source.host with sd_params.host
                  if [syslog_sd_params][host] {
                    mutate {
                      add_field => { "[@shipper][host]" => "%{[syslog_hostname]}" }
                      replace => { "[@source][host]" => "%{[syslog_sd_params][host]}" }
                    }
                  }
  
                  if [syslog_sd_params][type] {
                     # when the syslog params include a type, prepare the message for parsing by additional downstream parsing rules:
                     #  - Change the @type - this triggers downstream parsing rules
                     #  - @message_body = 'unparsed' message body that will be parsed by downstream @type rules
                     mutate {
                         replace => { "@type" => "%{syslog_sd_params[type]}" }
                     }
  
                  }
              }
          }
      }
  
      # @message should contain the remaining unparsed text
      mutate {
        rename => { "syslog_message" => "@message" }
      }
  
  }

}

if [syslog_program] == "nats-to-syslog" {
    # Parse BOSH NATS logs
  if [syslog_program] == "nats-to-syslog" {
    json {
      source => "@message"
      target => "NATS"
      add_field => { "[@level]" => "INFO" }
      add_tag => ["NATS"]
      remove_field => ["@message"]
    }
  
    if "_jsonparsefailure" in [tags] {
      mutate {
        add_tag => "fail/bosh_nats/json"
        remove_tag => "_jsonparsefailure"
      }
    } else {
  
      json {
        source => "[NATS][Data]"
        target => "[NATS][Data]"
      }
  
      if "_jsonparsefailure" in [tags] {
        mutate {
          add_tag => "fail/bosh_nats/Data/json"
          remove_tag => "_jsonparsefailure"
        }
      } else {
        if [NATS][Subject] =~ /hm\.agent\.heartbeat.*/ {
          mutate {
            add_field => { "[@source][vm]" => "%{[NATS][Data][job]}/%{[NATS][Data][index]}" }
            add_tag => ["hm_agent_heartbeat"]
          }
          mutate {
            rename => { "[NATS][Data][job]" => "[@source][job]" }
            rename => { "[NATS][Data][index]" => "[@source][index]" }
          }
          translate {
            field => "[@source][job]"
            destination => "[@source][deployment]"
            regex => true
            exact => true
            dictionary => [ "(elasticsearch_data|elasticsearch_master|firehose-to-syslog|ingestor|queue|parser|kibana|router).*", "Logsearch",
                            "(clock_global|cloud_controller|consul_server|diego_brain|diego_cell|diego_database|doppler|etcd_server|loggregator_trafficcontroller|nats|nfs_server|uaa|dea).*", "CF"
                          ]
            fallback => "Unknown"
          }
          mutate {
            convert => { "[NATS][Data][vitals][cpu][sys]" => "float" }
            convert => { "[NATS][Data][vitals][cpu][user]" => "float" }
            convert => { "[NATS][Data][vitals][cpu][wait]" => "float" }
            convert => { "[NATS][Data][vitals][disk][ephemeral][inode_percent]" => "float" }
            convert => { "[NATS][Data][vitals][disk][ephemeral][percent]" => "float" }
            convert => { "[NATS][Data][vitals][disk][system][inode_percent]" => "float" }
            convert => { "[NATS][Data][vitals][disk][system][percent]" => "float" }
            convert => { "[NATS][Data][vitals][mem][kb]" => "float" }
            convert => { "[NATS][Data][vitals][mem][percent]" => "float" }
            convert => { "[NATS][Data][vitals][swap][kb]" => "float" }
            convert => { "[NATS][Data][vitals][swap][percent]" => "float" }
          }
          if [NATS][Data][vitals][disk][persistent] {
            mutate {
              convert => { "[NATS][Data][vitals][disk][persistent][inode_percent]" => "float" }
              convert => { "[NATS][Data][vitals][disk][persistent][percent]" => "float" }
            }
          }
          ruby {
               code => "event['NATS']['Data']['vitals']['load'] = { 'avg01' => event['NATS']['Data']['vitals']['load'][0].to_f, 'avg05' => event['NATS']['Data']['vitals']['load'][1].to_f, 'avg15' =>\
        event['NATS']['Data']['vitals']['load'][2].to_f }"
          }
        } else if [NATS][Subject] =~ /hm\.(director|agent)\.alert.*/ {
          mutate {
            add_tag => "hm_alert"
          }
          date {
            match => [ "[NATS][Data][created_at]", "UNIX" ]
            tag_on_failure => "fail/NATS/hm_alert/date"
            remove_field => "[NATS][Data][created_at]"
          }
          translate {
            field => "[NATS][Data][severity]"
            destination => "[@level]"
            override => true
            dictionary => [
              "1", "FATAL",
              "2", "FATAL",
              "3", "ERROR",
              "4", "WARN" ]
            fallback => "INFO"
          }
        }
      }
    }
  }

}

if [syslog_program] == "haproxy" {
    grok {
    match => { "@message" => "%{IP:[haproxy][client_ip]}:%{INT:[haproxy][client_port]:int} \[%{DATA:[haproxy][accept_date]}\] %{NOTSPACE:[haproxy][frontend_name]} %{NOTSPACE:[haproxy][backend_name]}/%{NOTSPACE:[haproxy][server_name]} %{INT:[haproxy][time_queue_ms]:int}/%{INT:[haproxy][time_backend_connect_ms]:int}/%{NOTSPACE:[haproxy][time_duration_ms]:int} %{NOTSPACE:[haproxy][bytes_read]:int} %{NOTSPACE:[haproxy][termination_state]} %{INT:[haproxy][actconn]:int}/%{INT:[haproxy][feconn]:int}/%{INT:[haproxy][beconn]:int}/%{INT:[haproxy][srvconn]:int}/%{NOTSPACE:[haproxy][retries]:int} %{INT:[haproxy][srv_queue]:int}/%{INT:[haproxy][backend_queue]:int}" }
    match => { "@message" => "%{IP:[haproxy][client_ip]}:%{INT:[haproxy][client_port]:int} \[%{DATA:[haproxy][accept_date]}\] %{NOTSPACE:[haproxy][frontend_name]}:%{SPACE}%{GREEDYDATA:[haproxy][message]}" }
    match => { "@message" => "%{GREEDYDATA:[haproxy][message]}" }
    add_tag => [ "haproxy" ]
    remove_field => ["@message"]
    tag_on_failure => "fail/haproxy/grok"
  }
  
  date {
    match => [ "[haproxy][accept_date]", "dd/MMM/YYYY:HH:mm:ss.SSS" ]
    target => "[haproxy][accept_date]"
  }
  
  #Add some helpful descripions for the termination state
  translate {
    dictionary => [
      "CD", "Session unexpectedly aborted by client",
      "cD", "Client-side timeout expired",
      "sD", "Server-side timeout expired"
    ]
    field => "[haproxy][termination_state]"
    destination => "@message"
  }
  
  

}
