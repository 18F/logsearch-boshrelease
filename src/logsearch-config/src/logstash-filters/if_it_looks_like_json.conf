#If it looks like JSON, parse it as JSON
if [@message] =~ /^\{/ {
  # convert timestamp (if present) to string
  grok {
    match => { "@message" => "(?:\"timestamp\":(%{NUMBER:time}|\"%{NUMBER:time}\"))" }
  }

  mutate {
    convert => { "time" => "string" }
  }

  json {
    source => "@message"
    target => "parsed_json_data"
    add_tag => "json/auto_detect"
    remove_field => ["@message"]
  }

  if "_jsonparsefailure" in [tags] {

    mutate {
      remove_tag => [ "_jsonparsefailure" ]
    }

  } else {

    if [parsed_json_data][timestamp] {
      date {
        match => [ "[parsed_json_data][timestamp]", "ISO8601", "UNIX" ]
        add_tag => "json/hoist_@timestamp"
      }
      # Convert UNIX timestamps with nanosecond precision - eg, 1458655387.3279622 - into 14586553873279622
      ruby {
        code => "timestamp = event['time']; if timestamp =~ /\d+\.\d+/ then; event['@timestamp_ns'] = timestamp.split(/\.\d{3}/).last.to_i ; end"
      }
      mutate {
        remove_field => ["time"]
      }
    }

    #
    # Put the parsed_json_data into a top level field named after the @source.service|@source.component|@source.program|syslog_program
    #
    if [@source][service] {
       mutate { add_field => { "parsed_json_key" => "%{[@source][service]}" } }
    } else if [@source][program] {
       mutate { add_field => { "parsed_json_key" => "%{[@source][program]}" } }
    } else if [@source][component] {
       mutate { add_field => { "parsed_json_key" => "%{[@source][component]}" } }
    } else if [syslog_program] {
      mutate {
        add_field => { "parsed_json_key" => "%{syslog_program}"}
      }
    } else {
      mutate {
        add_field => { "parsed_json_key" => "unknown_source" }
      }
    }

    mutate {
      gsub => [
        "parsed_json_key", "[\s/\\?#-\.]", "_"
      ]
    }
    ruby {
      code => "event[event['parsed_json_key'].to_s.downcase] = LogStash::Util.normalize(event['parsed_json_data'])"
      remove_field => [ "parsed_json_key", "parsed_json_data" ]
    }
  }
}
